{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca4cbcba",
   "metadata": {},
   "source": [
    "# 05 Â· Model Evaluation\n",
    "Load the saved model (from a run) and compute metrics/plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead28bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, confusion_matrix, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FEAT_CSV = \"/mnt/data/IPO_Databricks_Notebooks/features.csv\"\n",
    "df = pd.read_csv(FEAT_CSV)\n",
    "\n",
    "y = df[\"Delisted\"].values\n",
    "X = df.drop(columns=[\"Delisted\",\"ipoDate\",\"delistingDate\"], errors=\"ignore\")\n",
    "\n",
    "# ðŸ‘‰ Replace with your MLflow run's model URI (or use last_run.txt if you store it)\n",
    "# For demo, we'll just re-train quickly here to evaluate.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "cat_cols = [c for c in X.columns if X[c].dtype == object]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"cats\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    (\"nums\", StandardScaler(), num_cols)\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "model = Pipeline([(\"pre\", pre), (\"clf\", LogisticRegression(max_iter=200))]).fit(X_train, y_train)\n",
    "\n",
    "y_prob = model.predict_proba(X_test)[:,1]\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "pr, rc, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"binary\", zero_division=0)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"AUC:\", auc, \"Precision:\", pr, \"Recall:\", rc, \"F1:\", f1)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_prob)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
